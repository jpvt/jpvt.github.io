<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Random Forest | João Pedro Vasconcelos</title>
    <link>https://jpvt.github.io/tag/random-forest/</link>
      <atom:link href="https://jpvt.github.io/tag/random-forest/index.xml" rel="self" type="application/rss+xml" />
    <description>Random Forest</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 02 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jpvt.github.io/media/icon_hu6e0ba196f4e113be19f679f5e0d6caf1_39320_512x512_fill_lanczos_center_2.png</url>
      <title>Random Forest</title>
      <link>https://jpvt.github.io/tag/random-forest/</link>
    </image>
    
    <item>
      <title>Metro Interstate Traffic Volume Analysis</title>
      <link>https://jpvt.github.io/post/metro_traffic_volume/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://jpvt.github.io/post/metro_traffic_volume/</guid>
      <description>&lt;h1 id=&#34;metro-interstate-traffic-volume-analysis&#34;&gt;Metro Interstate Traffic Volume Analysis&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this notebook, I will discuss the results of my second assignment of the class Introduction to Artificial Intelligence. My job was to predict the traffic volume on Metro Interstate with machine learning models. Finally, I will discuss my results and present some insights into the data.&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;The dataset used for this assignment is used by many people all over the world, mainly for learning purposes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;About:&lt;/strong&gt;
Hourly Interstate 94 Westbound traffic volume for MN DoT ATR station 301, roughly midway between Minneapolis and St Paul, MN. Hourly weather features and holidays included for impacts on traffic volume.&lt;/p&gt;
&lt;p&gt;This dataset is available at: &lt;a href=&#34;https://archive.ics.uci.edu/ml/machine-learning-databases/00492/&#34;&gt;https://archive.ics.uci.edu/ml/machine-learning-databases/00492/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;importing-packages&#34;&gt;Importing Packages&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Data Preprocessing Packages
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
import re

# Data Visualization Packages
import matplotlib.pyplot as plt
import seaborn as sns
import pandas_profiling as pf
from sklearn.ensemble import RandomForestRegressor

# Models and Metrics
from sklearn import model_selection, svm
from sklearn.svm import SVR
from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score, cross_val_predict,GridSearchCV, StratifiedKFold, KFold, RandomizedSearchCV, train_test_split

import xgboost as xgb
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;getting-the-data&#34;&gt;Getting the data:&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dataset = False

if dataset:
    df = pd.read_csv(&amp;quot;metro.csv&amp;quot;)
else:
    df = pd.read_csv(&amp;quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz&amp;quot;)


df.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;rain_1h&lt;/th&gt;
      &lt;th&gt;snow_1h&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;weather_description&lt;/th&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;traffic_volume&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;scattered clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 09:00:00&lt;/td&gt;
      &lt;td&gt;5545&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;broken clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 10:00:00&lt;/td&gt;
      &lt;td&gt;4516&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;overcast clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 11:00:00&lt;/td&gt;
      &lt;td&gt;4767&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;overcast clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 12:00:00&lt;/td&gt;
      &lt;td&gt;5026&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;broken clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 13:00:00&lt;/td&gt;
      &lt;td&gt;4918&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.info() #Basic information about each column
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 48204 entries, 0 to 48203
Data columns (total 9 columns):
holiday                48204 non-null object
temp                   48204 non-null float64
rain_1h                48204 non-null float64
snow_1h                48204 non-null float64
clouds_all             48204 non-null int64
weather_main           48204 non-null object
weather_description    48204 non-null object
date_time              48204 non-null object
traffic_volume         48204 non-null int64
dtypes: float64(3), int64(2), object(4)
memory usage: 3.3+ MB
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;descrições-do-dataset-valores-numéricos-e-categóricos&#34;&gt;Descrições do dataset, valores numéricos e categóricos&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.describe()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;rain_1h&lt;/th&gt;
      &lt;th&gt;snow_1h&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;traffic_volume&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;48204.000000&lt;/td&gt;
      &lt;td&gt;48204.000000&lt;/td&gt;
      &lt;td&gt;48204.000000&lt;/td&gt;
      &lt;td&gt;48204.000000&lt;/td&gt;
      &lt;td&gt;48204.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;td&gt;281.205870&lt;/td&gt;
      &lt;td&gt;0.334264&lt;/td&gt;
      &lt;td&gt;0.000222&lt;/td&gt;
      &lt;td&gt;49.362231&lt;/td&gt;
      &lt;td&gt;3259.818355&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;td&gt;13.338232&lt;/td&gt;
      &lt;td&gt;44.789133&lt;/td&gt;
      &lt;td&gt;0.008168&lt;/td&gt;
      &lt;td&gt;39.015750&lt;/td&gt;
      &lt;td&gt;1986.860670&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;td&gt;272.160000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;1193.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;td&gt;282.450000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;64.000000&lt;/td&gt;
      &lt;td&gt;3380.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;td&gt;291.806000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;90.000000&lt;/td&gt;
      &lt;td&gt;4933.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;td&gt;310.070000&lt;/td&gt;
      &lt;td&gt;9831.300000&lt;/td&gt;
      &lt;td&gt;0.510000&lt;/td&gt;
      &lt;td&gt;100.000000&lt;/td&gt;
      &lt;td&gt;7280.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.describe(include= &#39;object&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;weather_description&lt;/th&gt;
      &lt;th&gt;date_time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;48204&lt;/td&gt;
      &lt;td&gt;48204&lt;/td&gt;
      &lt;td&gt;48204&lt;/td&gt;
      &lt;td&gt;48204&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;unique&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;40575&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;top&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;sky is clear&lt;/td&gt;
      &lt;td&gt;2013-04-18 22:00:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;freq&lt;/th&gt;
      &lt;td&gt;48143&lt;/td&gt;
      &lt;td&gt;15164&lt;/td&gt;
      &lt;td&gt;11665&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h2 id=&#34;exploratory-data-analysis&#34;&gt;Exploratory Data Analysis:&lt;/h2&gt;
&lt;p&gt;It is extremely important to know the dataset well since in machine learning is the diversity in the experience that will guarantee success in carrying out a given task. Statistics in this process is very useful, as it provides descriptive measures that demonstrate the main characteristics of the data we are dealing with. Additionally, searching for information about the data and the problem to which it is linked can be of great help and even essential to improve the achievement of the desired task.
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;div&gt;
&lt;img src=&#34;bob_eda.jpg&#34; width=&#34;400&#34;/&gt;
&lt;/div&gt;
&lt;h3 id=&#34;about-the-data&#34;&gt;About the data:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Holiday: Indicates if the date is a holiday and if it specifies the holiday, if not &lt;strong&gt;None&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Temp: Indicates the temperature in Kelvin.&lt;/li&gt;
&lt;li&gt;rain_1h: Amount in mm of rain that occurred in the hour.&lt;/li&gt;
&lt;li&gt;snow_1h: Amount in mm of snow that occurred in the hour.&lt;/li&gt;
&lt;li&gt;clouds_all: Percentage of cloud cover.&lt;/li&gt;
&lt;li&gt;weather_main: Short textual description of the current weather.&lt;/li&gt;
&lt;li&gt;weather_description:  Longer textual description of the current weather.&lt;/li&gt;
&lt;li&gt;date_time: Hour of the data collected in local CST time.&lt;/li&gt;
&lt;li&gt;traffic_volume: Hourly I-94 ATR 301 reported westbound traffic volume.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;disponível em: &lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume&#34;&gt;https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first observations to be made with the information we have so far are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There is no missing data, but that does not mean that there is no inconsistent data.
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The date_time, a time stamp, is not defined as the pandas&#39; timestamp. The way it was extracted will not bring us any information and that is a big problem. Since in most cities, traffic occurs at rush hour.
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;There are temperature records at absolute zero, clearly inconsistent data.
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;rain_1h and snow_1h have many zeros and their distribution is not very well defined, since in rare moments they have high records.
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;99.9% of Holiday data is None, and the other data is spread over multiple holidays&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;holiday&#34;&gt;Holiday&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize = (16,6))
sns.countplot(y = df[&#39;holiday&#39;])
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_13_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;As normal days are much more frequent over the years of the dataset, then holidays are not visible in the Plot. To analyze them it is necessary to remove the normal days. Then I will categorize between Holiday and Non-Holiday&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;h_df = df[df[&#39;holiday&#39;] != &#39;None&#39;]
plt.figure(figsize = (16,6))
sns.countplot(y = h_df[&#39;holiday&#39;])
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_15_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;To solve this problem, I will recategorize all holidays as Holiday and leave them in the same category.&lt;/p&gt;
&lt;h3 id=&#34;temperature&#34;&gt;Temperature&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize = (16,8))
sns.boxplot(df[&#39;temp&#39;])
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_18_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;As seen before, some Outliers are at absolute zero, probably due to some error in capturing the temperature. Then I will remove the Outliers so as not to affect my result.&lt;/p&gt;
&lt;h3 id=&#34;rain-and-snow&#34;&gt;Rain and Snow&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize = (16,6))
sns.distplot(df[&#39;rain_1h&#39;], kde = True)
plt.show()

plt.figure(figsize = (16,6))
sns.distplot(df[&#39;snow_1h&#39;], kde = True)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_21_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_21_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;As can be seen, the features have many zeros and the distribution is skewed.&lt;/p&gt;
&lt;h3 id=&#34;clouds&#34;&gt;Clouds&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize = (16,6))
sns.distplot(df[&#39;clouds_all&#39;],)
plt.show()
df[&#39;clouds_all&#39;].describe()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_24_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;count    48204.000000
mean        49.362231
std         39.015750
min          0.000000
25%          1.000000
50%         64.000000
75%         90.000000
max        100.000000
Name: clouds_all, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It has many zeros, but does not appear to show any inconsistent data.&lt;/p&gt;
&lt;h3 id=&#34;weather-main-e-weather-description&#34;&gt;Weather Main e Weather Description&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.figure(figsize = (16,6))
sns.countplot(y = df[&#39;weather_main&#39;])
plt.show()

plt.figure(figsize = (16,8))
sns.countplot(y =df[&#39;weather_description&#39;])
plt.show()

confusion_matrix = pd.crosstab(df[&#39;weather_main&#39;], df[&#39;weather_description&#39;])
confusion_matrix.corr(method = &#39;spearman&#39;).style.background_gradient(cmap=&#39;coolwarm&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_27_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_27_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Since weather_description offers only an extension of the description of weather_main, it is probably not of interest to keep both for modeling. Since they carry correlated information, which can be seen in the matrix above.&lt;/p&gt;
&lt;h2 id=&#34;data-cleaning&#34;&gt;Data Cleaning&lt;/h2&gt;
&lt;p&gt;Now that the exploratory data analysis has been done, it will be necessary to clean the dataset, to guarantee the success of the model. The observations made at the EDA will be made below.&lt;/p&gt;
&lt;h3 id=&#34;holiday-parsing&#34;&gt;Holiday Parsing&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def holiday(holiday):
    cat = &#39;None&#39;
    if holiday != &#39;None&#39;:
        cat = &#39;Holiday&#39;
        
    return cat

df[&#39;holiday&#39;] = df[&#39;holiday&#39;].map(holiday)
df[&#39;holiday&#39;].unique()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;array([&#39;None&#39;, &#39;Holiday&#39;], dtype=object)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;parsing-do-date_time&#34;&gt;Parsing do date_time&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def parse_timestamp(df, datetime):
    df[datetime] = pd.to_datetime(df[datetime])
    df[&#39;Year&#39;] = df[datetime].dt.year
    df[&#39;Month&#39;] = df[datetime].dt.month
    df[&#39;Weekday&#39;] = df[datetime].dt.weekday
    df[&#39;Hour&#39;] = df[datetime].dt.hour
    
def categorize_hour(hour):    
    cat = &#39;None&#39;
    
    if hour in [1,2,3,4,5]:
        cat = &#39;dawn&#39;
    elif hour in [6,7,8,9,10,11,12]:
        cat = &#39;morning&#39;
    elif hour in [13,14,15,16,17,18]:
        cat = &#39;afternoon&#39;
    elif hour in [19,20,21,22,23,24]:
        cat = &#39;night&#39;
        
    return cat   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before parsing the date_time i will remove possible duplicates.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.drop_duplicates(inplace = True)
df.duplicated().sum()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;parse_timestamp(df, &#39;date_time&#39;)
#df[&#39;Hour&#39;] = df[&#39;Hour&#39;].map(categorize_hour)
df.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;rain_1h&lt;/th&gt;
      &lt;th&gt;snow_1h&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;weather_description&lt;/th&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;traffic_volume&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;Month&lt;/th&gt;
      &lt;th&gt;Weekday&lt;/th&gt;
      &lt;th&gt;Hour&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;scattered clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 09:00:00&lt;/td&gt;
      &lt;td&gt;5545&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;broken clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 10:00:00&lt;/td&gt;
      &lt;td&gt;4516&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;overcast clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 11:00:00&lt;/td&gt;
      &lt;td&gt;4767&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;overcast clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 12:00:00&lt;/td&gt;
      &lt;td&gt;5026&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;broken clouds&lt;/td&gt;
      &lt;td&gt;2012-10-02 13:00:00&lt;/td&gt;
      &lt;td&gt;4918&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.set_index(&#39;date_time&#39;,inplace = True)
df.sort_index()[&#39;traffic_volume&#39;].rolling(4000).mean().plot(figsize = (16,8))
plt.xlabel(&#39;Date Time&#39;)
plt.ylabel(&#39;Traffic Volume&#39;)
df.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;rain_1h&lt;/th&gt;
      &lt;th&gt;snow_1h&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;weather_description&lt;/th&gt;
      &lt;th&gt;traffic_volume&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;Month&lt;/th&gt;
      &lt;th&gt;Weekday&lt;/th&gt;
      &lt;th&gt;Hour&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 09:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;scattered clouds&lt;/td&gt;
      &lt;td&gt;5545&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 10:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;broken clouds&lt;/td&gt;
      &lt;td&gt;4516&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 11:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;overcast clouds&lt;/td&gt;
      &lt;td&gt;4767&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 12:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;overcast clouds&lt;/td&gt;
      &lt;td&gt;5026&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 13:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;broken clouds&lt;/td&gt;
      &lt;td&gt;4918&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;output_39_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;removing-weather_description&#34;&gt;Removing Weather_description&lt;/h3&gt;
&lt;p&gt;I have chosen to remove weather_description due to redundancy when placing with weather_main&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.drop(columns = [&#39;weather_description&#39;], inplace = True)
df.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;rain_1h&lt;/th&gt;
      &lt;th&gt;snow_1h&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;traffic_volume&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;Month&lt;/th&gt;
      &lt;th&gt;Weekday&lt;/th&gt;
      &lt;th&gt;Hour&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 09:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;5545&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 10:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;4516&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 11:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;4767&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 12:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;5026&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 13:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;4918&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h3 id=&#34;removendo-rain_1h-e-snow_1h&#34;&gt;Removendo rain_1h e snow_1h&lt;/h3&gt;
&lt;p&gt;As the distribution of rain_1h and snow_1h is not good and the vast majority of values are at zero, I will remove them, since the weather information includes whether it is raining, snowing, or neither.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.drop(columns = [&#39;rain_1h&#39;,&#39;snow_1h&#39;],inplace = True)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;traffic_volume&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;Month&lt;/th&gt;
      &lt;th&gt;Weekday&lt;/th&gt;
      &lt;th&gt;Hour&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 09:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;5545&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 10:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;4516&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 11:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;4767&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 12:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;5026&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 13:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;4918&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h3 id=&#34;feature-importance&#34;&gt;Feature Importance&lt;/h3&gt;
&lt;p&gt;I will run a Random Forest in order to find the importance of each feature for the result of traffic_volume. However, it is necessary to transform categorical data first.&lt;/p&gt;
&lt;h3 id=&#34;splitting-features-and-traffic-volume&#34;&gt;Splitting Features and Traffic Volume&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;feats = df.drop(&#39;traffic_volume&#39;,1).copy()
label = df[&#39;traffic_volume&#39;].copy()

feats.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;Month&lt;/th&gt;
      &lt;th&gt;Weekday&lt;/th&gt;
      &lt;th&gt;Hour&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 09:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 10:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 11:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 12:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 13:00:00&lt;/th&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;Clouds&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h3 id=&#34;copy-with-label-enconder-of-the-features&#34;&gt;Copy with Label Enconder of the features&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;le = LabelEncoder()
num_feats = feats.copy()

for column in num_feats.columns:
    if num_feats[column].dtype == &#39;object&#39;:
        num_feats[column] = le.fit_transform(num_feats[column])

num_feats.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;holiday&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;weather_main&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;Month&lt;/th&gt;
      &lt;th&gt;Weekday&lt;/th&gt;
      &lt;th&gt;Hour&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 09:00:00&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 10:00:00&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 11:00:00&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 12:00:00&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 13:00:00&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h3 id=&#34;copy-with-one-hot-enconding-of-the-features&#34;&gt;Copy with One Hot Enconding of the features&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;onehot_feats = feats.copy()
onehot_feats[[&#39;Year&#39;,&#39;Month&#39;,&#39;Weekday&#39;]] = feats[[&#39;Year&#39;,&#39;Month&#39;,&#39;Weekday&#39;]].astype(&#39;category&#39;)
onehot_feats = pd.get_dummies(onehot_feats)

onehot_feats.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;temp&lt;/th&gt;
      &lt;th&gt;clouds_all&lt;/th&gt;
      &lt;th&gt;Hour&lt;/th&gt;
      &lt;th&gt;holiday_Holiday&lt;/th&gt;
      &lt;th&gt;holiday_None&lt;/th&gt;
      &lt;th&gt;weather_main_Clear&lt;/th&gt;
      &lt;th&gt;weather_main_Clouds&lt;/th&gt;
      &lt;th&gt;weather_main_Drizzle&lt;/th&gt;
      &lt;th&gt;weather_main_Fog&lt;/th&gt;
      &lt;th&gt;weather_main_Haze&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;Month_10&lt;/th&gt;
      &lt;th&gt;Month_11&lt;/th&gt;
      &lt;th&gt;Month_12&lt;/th&gt;
      &lt;th&gt;Weekday_0&lt;/th&gt;
      &lt;th&gt;Weekday_1&lt;/th&gt;
      &lt;th&gt;Weekday_2&lt;/th&gt;
      &lt;th&gt;Weekday_3&lt;/th&gt;
      &lt;th&gt;Weekday_4&lt;/th&gt;
      &lt;th&gt;Weekday_5&lt;/th&gt;
      &lt;th&gt;Weekday_6&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;date_time&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 09:00:00&lt;/th&gt;
      &lt;td&gt;288.28&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 10:00:00&lt;/th&gt;
      &lt;td&gt;289.36&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 11:00:00&lt;/th&gt;
      &lt;td&gt;289.58&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 12:00:00&lt;/th&gt;
      &lt;td&gt;290.13&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2012-10-02 13:00:00&lt;/th&gt;
      &lt;td&gt;291.14&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 42 columns&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&#34;feature-importance---label-encoder&#34;&gt;Feature Importance - Label Encoder&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = RandomForestRegressor(random_state=1, max_depth=10)
model.fit(num_feats,label)

#Plot
features = feats.columns
importances = model.feature_importances_
indices = np.argsort(importances)[-5:] #Top 5 features
plt.title(&#39;Feature Importances&#39;)
plt.barh(range(len(indices)), importances[indices], color=&#39;b&#39;, align=&#39;center&#39;)
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel(&#39;Relative Importance&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_53_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;feature-importance---one-hot-encoding&#34;&gt;Feature Importance - One Hot Encoding&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = RandomForestRegressor(random_state=1, max_depth=10)
model.fit(onehot_feats,label)
#Plot t
features = onehot_feats.columns
importances = model.feature_importances_
indices = np.argsort(importances)[-10:] #Top 10 features
plt.title(&#39;Feature Importances&#39;)
plt.barh(range(len(indices)), importances[indices], color=&#39;b&#39;, align=&#39;center&#39;)
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel(&#39;Relative Importance&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_55_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;It is clear now that the hour feature is the one that most influences the traffic volume. This can be commonly observed in big cities where at rush hour the traffic volume is high.&lt;/p&gt;
&lt;h2 id=&#34;scaling&#34;&gt;Scaling&lt;/h2&gt;
&lt;p&gt;Necessary to keep the numerical values in a range and consequently one feature does not stand out much more than the other when training the model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X = num_feats.values
X = preprocessing.scale(X)
y = label.values

print(X)
print(y)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[[ 0.03560205  0.53041592 -0.24004863 ...  1.02779521 -0.98947829
  -0.34548099]
 [ 0.03560205  0.61138394  0.65704665 ...  1.02779521 -0.98947829
  -0.20139502]
 [ 0.03560205  0.62787742  1.04151605 ...  1.02779521 -0.98947829
  -0.05730906]
 ...
 [ 0.03560205  0.11433026  1.04151605 ...  0.73369913  1.50301966
   1.38355059]
 [ 0.03560205  0.06634921  1.04151605 ...  0.73369913  1.50301966
   1.52763656]
 [ 0.03560205  0.06859832  1.04151605 ...  0.73369913  1.50301966
   1.67172252]]
[5545 4516 4767 ... 2159 1450  954]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;train-and-test&#34;&gt;Train and Test&lt;/h2&gt;
&lt;h3 id=&#34;holdout07-03&#34;&gt;Holdout(0.7; 0.3)&lt;/h3&gt;
&lt;p&gt;The dataset will be randomly split between training and testing. For this task, we will divide 70% for training, while the rest will be used for testing.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state = 42)
X_train.shape
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(33730, 8)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;random-forest&#34;&gt;&lt;strong&gt;Random Forest&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;It is a supervised ML(Machine Learning) algorithm. Creates several decision trees and combines them to obtain a better prediction.
&lt;br/&gt;
&lt;br/&gt;
Random forest adds randomness to the model when creating trees. It searches for the best attribute in a random subset of the attribute. This creates diversity and generates better models. For this reason, it was possible to find the importance of attributes, performed previously.
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Can be used for classification and regression.&lt;/li&gt;
&lt;li&gt;Handles missing values well.&lt;/li&gt;
&lt;li&gt;It will hardly overfit the model.&lt;/li&gt;
&lt;li&gt;Handles large, high dimensional data sets very well (Main reason for choosing this method)
&lt;br/&gt;
&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The programmer does not have much control on the model, it generates black box.
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Random Forest Example:&lt;/strong&gt;&lt;/p&gt;
&lt;div&gt;
&lt;img src=&#34;random_forest.png&#34; width=&#34;500&#34;/&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;reg = RandomForestRegressor()
reg = reg.fit(X_train,y_train)
predict = reg.predict(X_test)
accuracy = reg.score(X_test, y_test)
mae = mean_absolute_error(y_test, predict)

print(f&amp;quot;R2 Score: {round(accuracy * 100, 3)}%&amp;quot;)
print(f&amp;quot;Mean Absolute Error: {round(mae, 4)}&amp;quot;)
print(f&#39;RMSE: {round(np.sqrt(mean_squared_error(y_pred=predict,y_true=y_test)),4)}&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;R2 Score: 95.901%
Mean Absolute Error: 221.4494
RMSE: 405.0598
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;xgboost&#34;&gt;XGBoost&lt;/h3&gt;
&lt;p&gt;It is an implementation of the Gradient Boost supervised ML algorithm, famous for its speed and performance. Gradient Boost tries to predict a target variable, for this it combines a group of estimates from a set of simpler and &amp;lsquo;weaker&amp;rsquo; models and transforms them into a &amp;lsquo;stronger&amp;rsquo; model.
&lt;br/&gt;
&lt;br/&gt;
&lt;strong&gt;Gradient Boosting Example:&lt;/strong&gt;&lt;/p&gt;
&lt;div&gt;
&lt;img src=&#34;gradboost.png&#34; width=&#34;350&#34;/&gt;
&lt;/div&gt;
&lt;p&gt;In this example, it can be seen that Gradient Boosting is a method in which new models are trained to resolve errors from previous models.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;xgb_model = xgb.XGBRegressor(objective=&amp;quot;reg:squarederror&amp;quot;,  n_estimators=1000, random_state=42,n_jobs=-1)
xgb_model.fit(X_train,y_train,early_stopping_rounds=10,eval_set=[(X_test, y_test)],verbose = 0)
y_pred = xgb_model.predict(X_test)

xgb_mae = mean_absolute_error(y_test, y_pred)
print(f&#39;R2 Score: {round(xgb_model.score(X_test,y_test)*100,2)}&#39;)
print(f&#39;RMSE: {np.sqrt(mean_squared_error(y_pred=y_pred,y_true=y_test))}&#39;)
print(f&amp;quot;Mean Absolute Error: {round(xgb_mae, 4)}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;R2 Score: 96.19
RMSE: 390.32545493877905
Mean Absolute Error: 232.6679
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;cross-validation&#34;&gt;Cross-Validation&lt;/h2&gt;
&lt;p&gt;In this method, the dataset is divided into K parts, while K-1 parts are used for training the remaining partition is used for testing until all the dataset is utilized. The validation of each forecast made is saved in a list and then the average of each metric will be made.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=42)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;random-forest-1&#34;&gt;Random Forest&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rmse = []
r2 = []
mae_l = []
for train_index, test_index in kf.split(X):
    reg_kf = RandomForestRegressor()
    reg_kf.fit(X[train_index],y[train_index])
    y_pred = reg_kf.predict(X[test_index])
    actuals = y[test_index]
    rmse.append(np.sqrt(mean_squared_error(actuals, y_pred)))
    r2.append(r2_score(actuals,y_pred))
    mae_l.append(mean_absolute_error(actuals, y_pred))


avg_r2 = np.mean(r2)
avg_rmse = np.mean(rmse)
avg_mae = np.mean(mae_l)
print(f&#39;AVG R2 Score :{round(avg_r2,3)*100}%\t Average RMSE:{avg_rmse}\t Average MAE:{round(avg_mae, 4)}&#39;)    
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;AVG R2 Score :95.7%	 Average RMSE:409.69403930472544	 Average MAE:217.4925
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;xgboost-1&#34;&gt;XGBoost&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rmse = []
r2 = []
mae_l = []
for train_index, test_index in kf.split(X):
    xgb_model = xgb.XGBRegressor(objective=&amp;quot;reg:squarederror&amp;quot;,  n_estimators=1000, random_state=42,n_jobs=-1)
    xgb_model.fit(X[train_index],y[train_index],early_stopping_rounds=10,eval_set=[(X[test_index], y[test_index])], verbose = 0)
    predictions = xgb_model.predict(X[test_index])
    actuals = y[test_index]
    rmse.append(np.sqrt(mean_squared_error(actuals, predictions)))
    r2.append(r2_score(actuals,predictions))
    mae_l.append(mean_absolute_error(actuals, predictions))

avg_r2 = np.mean(r2)
avg_rmse = np.mean(rmse)
avg_mae = np.mean(mae_l)
print(f&#39;AVG R2 Score :{round(avg_r2,3)*100}%\t Average RMSE:{avg_rmse}\t Average MAE:{round(avg_mae, 4)}&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;AVG R2 Score :96.1%	 Average RMSE:390.5595082859465	 Average MAE:229.8818
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;results-and-discussion&#34;&gt;Results and Discussion:&lt;/h2&gt;
&lt;p&gt;The metrics chosen for the evaluation of the models were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;RMSE(Root Mean Squared Error), average of the difference between the actual and the predicted value.&lt;/li&gt;
&lt;li&gt;MAE(Mean Absolute Error), module mean of the difference between the actual and the predicted value.&lt;/li&gt;
&lt;li&gt;R²(R Squared), it is a measure that demonstrates how much the model explains the variance of the real value. It varies between zero and one, the closer to one the more adjusted to the sample is the model.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; From the results presented for each model, it is noticeable that the forecasts fit well with the expected sample. The Holdout method showed better efficiency for the problem than the cross-validation, although the results are not so different. The XGBoost algorithm obtained forecasts with less error and more adjusted to the original sample.
&lt;br/&gt;
&lt;p&gt; Despite the satisfying result of the predictive models, they may not be efficient for certain applications, like a route recommendation system, where the value must be very precise. To solve this problem, the next works are expected to implement specific models for time-based problems, such as Recurrent Neural Networks (RNN) and ARIMA, since the features that are most relevant to the problem are related to time series.
</description>
    </item>
    
  </channel>
</rss>
